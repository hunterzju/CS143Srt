0
00:00:03,830 --> 00:00:08,580
In this video, we're going to transition from lexical analysis to parsing and talk
在这段视频中，我们将从词汇分析过渡到解析和交谈

1
00:00:08,580 --> 00:00:15,580
a little bit about the relationship between those two compiler phases. We've
稍微了解一下这两个编译器阶段之间的关系。我们已经

2
00:00:16,660 --> 00:00:20,560
already talked about regular languages and it's worth mentioning that these are the
我已经讨论过常规语言，值得一提的是，这些是

3
00:00:20,560 --> 00:00:24,810
weakest formal languages that are widely used. But they have, of course, many
被广泛使用的最弱的正式语言。但是，当然，他们有很多

4
00:00:24,810 --> 00:00:30,150
applications, some of which we saw in previous videos. The difficulty with
应用程序，其中一些我们在前面的视频中看到过。它的困难之处在于

5
00:00:30,150 --> 00:00:35,110
regular languages is that a lot of languages are simply not regular. And
规则语言就是很多语言根本就是不规则的。和

6
00:00:35,110 --> 00:00:39,699
there's some pretty important languages that can't be expressed using regular
有一些非常重要的语言不能用常规语言来表达

7
00:00:39,699 --> 00:00:44,199
expressions or finite automata. So let's consider this language which is the set of
表达式或有限自动机。让我们考虑一下这门语言，它是

8
00:00:44,199 --> 00:00:50,269
all balanced parentheses. So some elements of this language would be at the string
所有的括号都是对齐的。因此，这种语言的某些元素会在字符串中

9
00:00:50,269 --> 00:00:56,210
one open-paren, one close-paren, two open-parens, two close-parens, three
一个左右手，一个左右手，两个左右手，两个左右手，三个

10
00:00:56,210 --> 00:01:02,290
open-parens, three close-parens and so on. And, you can imagine that this is actually
左右撇子、三个右撇子，以此类推。你可以想象这实际上是

11
00:01:02,290 --> 00:01:05,580
something that's fairly representative of lots of programming language construct. So
一些相当能代表大量编程语言构造的东西。所以

12
00:01:05,580 --> 00:01:12,580
for example, any kind of nested arithmetic expression would fit into this class but
例如，任何类型的嵌套算术表达式都适合此类，但是

13
00:01:13,470 --> 00:01:20,470
also things like nested if and else's will have this category, this characteristic.
像嵌套的if和Else这样的东西也会有这个类别，这个特征。

14
00:01:21,640 --> 00:01:26,380
And here with the nested [inaudible] it's just the f statement, the functions like
这里嵌套的[听不见]只有f语句，函数如下

15
00:01:26,380 --> 00:01:32,490
an open-paren. Not every languages like cool which has the explicit closing fee as
一位敞开心扉的帕伦。并不是每种语言都像Cool一样，它有明确的结束费，比如

16
00:01:32,490 --> 00:01:36,450
well but they're implicit in many languages and so there are lots of nesting
嗯，但是它们在许多语言中都是隐含的，所以有很多嵌套

17
00:01:36,450 --> 00:01:43,450
structure in programming languages constructs and those cannot be handled by
结构在编程语言构造中，而这些构造不能由

18
00:01:43,690 --> 00:01:50,040
regular expressions. So this raises the question of what the regular languages can
正则表达式。因此，这就提出了一个问题，即常规语言可以

19
00:01:50,040 --> 00:01:56,430
express. And, why they aren't sufficient for recognizing arbitrary nesting
快递。还有，为什么它们不足以识别任意嵌套

20
00:01:56,430 --> 00:02:01,240
structure. So we can illustrate the limitations of regular languages and
结构。所以我们可以说明常规语言的局限性

21
00:02:01,240 --> 00:02:05,860
Finite Automaton by looking a simple two state machine. So let's consider this
通过看一个简单的双状态机来实现有限自动机。所以让我们考虑一下这个

22
00:02:05,860 --> 00:02:10,330
machine. We have one we have start state and then the other state is the accepting
机器。我们有一个状态，我们有开始状态，然后另一个状态是接受

23
00:02:10,330 --> 00:02:16,700
state. And, we'll have this machine. Just be a machine that we've already seen
州政府。还有，我们要买这台机器。只是做一台我们已经见过的机器

24
00:02:16,700 --> 00:02:23,700
actually and it'll recognize strings with odd numbers of 1's. So if we see a one and
实际上，它会识别带有奇数个1的字符串。所以如果我们看到一个1和

25
00:02:25,620 --> 00:02:29,920
we're in the start state, we move. We now see an odd number of 1's. We move to the
我们处于开始状态，我们开始行动。我们现在看到奇数个1。我们移到

26
00:02:29,920 --> 00:02:32,840
accepting state and we stay there until we see another one. In which case, we've seen
接受状态，我们呆在那里直到我们看到另一个状态。在这种情况下，我们已经看到

27
00:02:32,840 --> 00:02:35,950
even number of 1's and then we're in the start state. So whenever we see an odd
偶数个1，然后我们就处于开始状态。所以每当我们看到奇怪的

28
00:02:35,950 --> 00:02:39,540
number of 1's, we're in the final state. Whenever we see an even number of 1's,
数到1，我们就到最后状态了。每当我们看到偶数个1的时候，

29
00:02:39,540 --> 00:02:44,250
we're in the start state. And if we feed this a fairly long string of 1's, let's,
我们现在处于启动状态。如果我们输入一串相当长的1，让我们，

30
00:02:44,250 --> 00:02:49,240
let's select only seven 1's in it. Then what's it going to do is going to go back
让我们只选择其中的七个1。那么它要做的就是回到

31
00:02:49,240 --> 00:02:52,890
and forth and back and forth between these states. It's gonna wind up in the final
在这些州之间来来回回。它会在决赛中结束

32
00:02:52,890 --> 00:02:57,160
state when it gets to the last one so it'll accept but notice that it doesn't
当它到达最后一个时声明，这样它就会接受，但请注意，它不会

33
00:02:57,160 --> 00:03:01,950
know how many times it's been to that final state. It doesn't remember the
知道它已经到达那个最终状态多少次了。它不记得

34
00:03:01,950 --> 00:03:04,880
length of the string; it doesn't have any way of counting how many characters the
字符串的长度；它没有任何方法来计算

35
00:03:04,880 --> 00:03:11,880
string had in it. And in fact, all I can count here is the parity. So in general
绳子在里面。事实上，我在这里所能计算的就是奇偶性。所以大体上来说

36
00:03:12,860 --> 00:03:19,580
Finite Automata can really only express things where you can count modulus on k.
有限自动机实际上只能表示可以计算k上的模数的东西。

37
00:03:19,580 --> 00:03:26,580
So they can count mod k for some k where k is the number of states in the machine.
所以他们可以计算mod，k，这里k是机器中的状态数。

38
00:03:27,349 --> 00:03:30,930
And so, you know if I have pre-test the machine, I can keep track of whether the
所以，你知道，如果我预先测试了机器，我可以跟踪

39
00:03:30,930 --> 00:03:35,629
string length is divisible by three or some other similar property but I can't do
字符串长度可以被3或其他类似属性整除，但我不能这样做

40
00:03:35,629 --> 00:03:42,629
things like count to an arbitrary i so if I need to recognize a language that
像任意的I这样的东西，所以如果我需要识别一种语言，

41
00:03:42,849 --> 00:03:46,510
requires counting arbitrarily high like recognizing all strings of balance
需要任意高的计数，就像识别所有的平衡字符串一样

42
00:03:46,510 --> 00:03:53,510
parentheses, we can't do that with the finite set of states. So what does a
括号中，我们不能用有限的状态集做到这一点。那么，一个

43
00:03:53,720 --> 00:03:58,940
parser do, it takes the sequence of tokens as input from the lexer and it produces a
解析器这样做，它从词法分析器获取标记序列作为输入，并生成一个

44
00:03:58,940 --> 00:04:05,940
parse tree of the program. And for example in cool, here's an input expression that
程序的解析树。例如，在COOL中，这里有一个输入表达式，它

45
00:04:08,700 --> 00:04:14,510
is input to the lexical analyzer. The lexical analyzer produces this sequence of
输入到词法分析器。词法分析器生成以下序列

46
00:04:14,510 --> 00:04:19,479
tokens as its output. That's the input to the parser. Then the parser produces this
令牌作为其输出。这是解析器的输入。然后解析器生成以下内容

47
00:04:19,478 --> 00:04:24,469
parse tree where the nesting structure has been made explicit. So, we have the, if
解析树，其中嵌套结构已显式显示。所以，我们有，如果

48
00:04:24,469 --> 00:04:28,460
and else and then the three components: the predicate, the then branch and the
然后是三个组件：谓词、THEN分支和

49
00:04:28,460 --> 00:04:35,460
else branch of the, if To summarize, the lexer takes a string of character as input
的Else分支，如果要总结，词法分析器接受字符串作为输入

50
00:04:36,150 --> 00:04:41,289
and produces a string of tokens as output. That string of tok ens is the input to the
并产生一串令牌作为输出。该令牌Ens字符串是

51
00:04:41,289 --> 00:04:47,300
parser which takes a string of tokens and produces a Parse Tree of the program. And
解析器，它接受一串令牌并生成程序的解析树。和

52
00:04:47,300 --> 00:04:50,719
it's worth mentioning a couple of thing here. First of all, sometimes the Parse
这里值得一提的是几件事。首先，有时语法分析

53
00:04:50,719 --> 00:04:57,430
Tree is only implicit. So the, a compiler may never actually build the full Parse
树只是隐式的。因此，编译器可能永远不会真正构建完整的Parse

54
00:04:57,430 --> 00:05:02,300
Tree. We'll talk more about that later. Many compilers do build an explicit parse
树。我们稍后会详细讨论这一点。许多编译器确实构建了显式解析

55
00:05:02,300 --> 00:05:06,699
tree but many do not. The other thing that's worth mentioning is that there are
树，但很多人没有。另一件值得一提的是，有

56
00:05:06,699 --> 00:05:11,949
compilers that do combine these two phases into one where everything is done by the
编译器将这两个阶段合并为一个阶段，其中所有工作都由

57
00:05:11,949 --> 00:05:16,029
parser. So, the parsing technology is generally powerful enough to express
解析器。因此，解析技术通常足够强大，可以表达

58
00:05:16,029 --> 00:05:21,319
lexical analysis in addition to parsing. But most compilers still divide up the
除了解析之外，还可以进行词法分析。但是大多数编译器仍然将

59
00:05:21,319 --> 00:05:25,729
work this way because regular expressions are such a good match for lexical analysis
这样做是因为正则表达式与词法分析非常匹配

60
00:05:25,729 --> 00:05:28,279
and then the parsing is handled separately.
然后分别进行解析。

